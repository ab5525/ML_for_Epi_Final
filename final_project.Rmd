---
title: "Final_Project"
output: html_document
date: "`r Sys.Date()`"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(pacman)

pacman::p_load(pacman, Amelia, caret, cluster, devtools, factoextra, gbm, GGally, ggplot2, ggthemes, 
  ggvis, ggbiplot,httr, knitr,lubridate, plotly, pROC,randomForest, rio, rpart, rpart.plot, rmarkdown, shiny, 
  stringr, stats,tidyr, tidyverse) 

set.seed(123)
```

Introduction: Public health officials have historically had difficulty understanding the reasons that people resist recommendations. During the covid-19 pandemic, vaccinations, the following booster campaigns ran into resistance preventing them from being fully effective. We believe that using data collected from individuals could provide predictions on whom is most likely to be vaccinated, get the disease, and the reasons for each of those. Our models will take into account social factors, risks, and pandemic fear and attempt to provide insight into the behavior of individuals in the population. 

### Load Data

```{r process_data}
df <- import('data/C3longitudinal_clean.csv')
info_cols <- c('STATE','RecSource','age','household_size','air_travel','gender','race')
risk_cols <- c('smokeV0','esmokeV0','antiviral','alcohol_use')
interest_cols <- c('early_vax_interest','delay_side_effects','delay_inconvenient','delay_trust')
                  
children_cols <- c('children_delay_se','children_delay_incon','children_delay_trust')

exposure_cols <- c('swimming_1','park_1','swimming_2','park_2',
                   'movie_1','mall_1','church_1','movie_2','mall_2','church_2')

#removed from above becasue people werent consistent on it 
no_exposure <- c('no_exp','no_exp2')

outcome_cols <- c('had_covid','booster','vaccinated','vax_comb')

risk_exposure <- c(exposure_cols, risk_cols)

df[,interest_cols]
```

```{r Some simplification}
set.seed(123)

df <- na.omit(df)
library(dplyr)


#combine the exposure columns a bit
df <- df %>% mutate(
   delay_any = as.logical(delay_side_effects + delay_inconvenient + delay_trust),
   combined_1 = as.logical(swimming_1 + park_1 + movie_1 + mall_1 + church_1 + air_travel),
   combined_2 = as.logical(swimming_2 + park_2 + movie_2 + mall_2 + church_2),
   combined_any = as.logical(swimming_1 + park_1 + movie_1 + mall_1 + church_1 
                             + swimming_2 + park_2 + movie_2 + mall_2 + church_2 + air_travel),
)

#change logical columns to factors 
#df.lgl <- colnames(df[,sapply(df,is.logical)])
df[,outcome_cols] <- lapply(df[,outcome_cols], factor)
df
```

```{r propensity scoring}
# logistic regression for if someone ever went to exposure locations based on race, age, gender etc.  
ps.model.logit <- glm(combined_any ~ age + gender + race ,
                    data=df, family=binomial(link="logit"))
    summary(ps.model.logit)
    
    # estimates odds of eversmoke, then convert to probability (aka the propensity score)
    prop.score <- (predict(ps.model.logit, df, type="response"))
    df$PS <- prop.score
    
    # Logistic Regression model can be misspecified rather easily. Example, do age and smoking have a linear relationship?
    
   #temp<-table(nmesdata$eversmk, df$LASTAGE) 
    #pct.eversmk <- 100*(temp[2, ] / (temp[2,] + temp[1,]))
    #plot(40:94, pct.eversmk, xlab="Age", ylab="% ever smokers", pch=".", cex=7, cex.lab=1.5, cex.axis=1.5)
```
```{r}
train.index<-createDataPartition(y=df$vaccinated,p=0.7,list=FALSE)
fdf.train <- df[train.index,]
fdf.test <- df[-train.index,]



df1 <- df[, c(no_exposure,risk_exposure,'PS','had_covid','vaccinated')]
#df1 <- df[, c("combined_any",no_exposure,risk_cols,'PS','had_covid','vaccinated')]

train.index<-createDataPartition(y=df$had_covid,p=0.7,list=FALSE)
df.train <- df1[train.index,]
df.test <- df1[-train.index,]


df1 <- df[, c(risk_exposure,interest_cols,'PS','vaccinated')]
train.index2<-createDataPartition(y=df$vaccinated,p=0.7,list=FALSE)
df.train2 <- df1[train.index2,]
df.test2 <- df1[-train.index2,]


summary(df.train)
```


### Unsupervised learning and clustering

```{r unsupervised}
dist.matrix <- dist(df[,interest_cols], method="euclidean")
h <- hclust(dist.matrix, method="complete")
plot(h)

silhouette_score <- function(k){
    cluster <- cutree(tree=h, k=k)
    ss <- silhouette(cluster, dist.matrix)
    mean(ss[, 3])
}

k <- 2:20

avg_sil <- sapply(k, silhouette_score)
sil_df <- data.frame(Clusters=k, Score=avg_sil)
p <- ggplot(sil_df, mapping=aes(x=Clusters, y=Score)) + geom_point(size=3) + labs(x="Number of Clusters", y="Silhouette Score") +
          theme(axis.line = element_line(colour = "black"), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), panel.background = element_rect(fill = 'white'))

print(p)

### although 2 clusters shows the highest silhouette score, it is not particularly informative (probably tells us only people who are interested vs not interested). 7 clusters seems to show a marked increase in score from 6 clusters, so that may be the best option to show patterns in vaccine interest.

clustering <- cutree(tree=h, k=7)
clustering <- as.factor(clustering)
df$interest_cluster <- clustering

### each cluster has a different approach to interest. For example, cluster 1 are interested in vaccines early, and will not be delayed for any reason. Cluster 2 are interested in vaccines early, but they would delay for side effects and inconveniences for themselves although not for their children. Etc.

df[df$interest_cluster == 1, interest_cols]
```


### logistic regression predictions
```{r logistic regression}

logit <- glm(had_covid ~ PS  + antiviral + booster+alcohol_use + air_travel + combined_2,
                    data=df, family=binomial(link="logit"))
summary(logit)

control.obj<-trainControl(method="cv", number=5)
fam <- 'binomial'

set.seed(123)
logit<-train(vaccinated~ PS + hoax + early_vax_interest +antiviral+combined_any, data=fdf.train, method="glm", family=fam, preProcess=c("center", "scale"), trControl=control.obj)

logit$results
confusionMatrix(logit)
coef(logit$finalModel)

logit.prob<- logit %>% predict(fdf.test)

cm = confusionMatrix(logit.prob, fdf.test$vaccinated, positive = 'TRUE')
cm

###### Had covid
control.obj<-trainControl(method="cv", number=5)

set.seed(123)
logit<-train(had_covid~ PS + hoax+ booster + antiviral + early_vax_interest+alcohol_use + air_travel + combined_any, data=fdf.train, method="glm", family=fam, preProcess=c("center", "scale"), trControl=control.obj)

logit$results
confusionMatrix(logit)
coef(logit$finalModel)

logit.prob<- logit %>% predict(fdf.test)

cm = confusionMatrix(logit.prob, fdf.test$had_covid, positive = 'TRUE')
cm
```
```{r svm attempt}
set.seed(123)

control.obj<-trainControl(method="cv", number=5)

svc.model<-train(vaccinated~ PS  + early_vax_interest +antiviral+combined_1, data=fdf.train, method="svmLinear", trControl=control.obj, preProcess=c("center", "scale"), probability=TRUE, tuneGrid=expand.grid(C=seq(0.0001,100, length=5)))

svc.model$bestTune
svc.model$results
confusionMatrix(svc.model)

svc.prob<- svc.model %>% predict(fdf.test)
cm = confusionMatrix(svc.prob, fdf.test$vaccinated, positive = 'TRUE')
cm
```

```{r random forest tuning}

feat.count<-c((ncol(df.train)-1)/2, sqrt(ncol(df.train)-1), (ncol(df.train)-1))

grid.rf<-expand.grid(mtry=feat.count)

control.obj<-trainControl(method="cv", number=5, sampling = 'up')

tree.num<-seq(100,300, by=100)
results.trees<-list()
for (ntree in tree.num){
  set.seed(123)
    rf.model<-train(had_covid~., data=df.train, method="rf", trControl=control.obj, metric="Accuracy", tuneGrid=grid.rf, importance=TRUE, ntree=ntree)
    index<-toString(ntree)
  results.trees[[index]]<-rf.model$results
}

output <-bind_rows(results.trees, .id = "ntrees")
best.tune<-output[which.max(output[,"Accuracy"]),]
best.tune$mtry
results.trees
mtry.grid<-expand.grid(.mtry=best.tune$mtry)

######
#predicting vaccination
feat.count2<-c(sqrt(ncol(df.train2)-1), log(ncol(df.train2)-1))
grid.rf2<-expand.grid(mtry=feat.count2)
control.obj2<-trainControl(method="cv", number=5)

tree.num<-seq(100,300, by=100)
results.trees2<-list()

for (ntree in tree.num){
  set.seed(123)
    rf.model2<-train(vaccinated~ PS + hoax + antiviral + early_vax_interest + combined_1, data=fdf.train, method="rf", trControl=control.obj2, metric="Accuracy", tuneGrid=grid.rf2, importance=TRUE, ntree=ntree)
    index<-toString(ntree)
  results.trees2[[index]]<-rf.model2$results
}

output2 <-bind_rows(results.trees2, .id = "ntrees")
best.tune2<-output2[which.max(output2[,"Accuracy"]),]
best.tune2$mtry
results.trees2
mtry.grid2<-expand.grid(.mtry=best.tune2$mtry)

```

```{r random forest model}
set.seed(123)
    rf.model<-train(had_covid~., data=df.train, method="rf", trControl=control.obj, metric="Accuracy", tuneGrid=mtry.grid, importance=TRUE,ntree=as.numeric(best.tune$ntrees))

confusionMatrix(rf.model)
varImp(rf.model)

######
#Model for vaccinated 
set.seed(123)
    rf.model2<-train(vaccinated~ age + race + hoax + early_vax_interest + combined_any, data=fdf.train, method="rf", trControl=control.obj2, metric="Accuracy", tuneGrid=mtry.grid2, importance=TRUE,ntree=as.numeric(best.tune2$ntrees))

confusionMatrix(rf.model2)
varImp(rf.model2)
```
# Prediction on test set 

```{r test_set}

#Predict in test-set and output probabilities
rf.preds<- rf.model %>% predict(df.test)
rf.preds2<- predict(rf.model, df.test, type="prob")

#Pull out predicted probabilities for Diabetes=Yes
rf.probability<-rf.preds2[,2]

cm = confusionMatrix(rf.preds, df.test$had_covid, positive = 'TRUE')
cm
'
#Predict in test-set and output probabilities
rf.preds<- rf.model2 %>% predict(df.test2)
rf.preds2<- predict(rf.model2, df.test2, type="prob")

#Pull out predicted probabilities for Diabetes=Yes
rf.probability<-rf.preds2[,2]
'

#cm = confusionMatrix(rf.preds, df.test2$vaccinated, positive = 'TRUE')
#cm

rf.preds<- rf.model2 %>% predict(fdf.test)
rf.preds2<- predict(rf.model2, fdf.test, type="prob")

#Pull out predicted probabilities for Diabetes=Yes
rf.probability<-rf.preds2[,2]

cm = confusionMatrix(rf.preds, fdf.test$vaccinated, positive = 'TRUE')
cm

```


# plotting
```{r plotting_calibration}
pred.prob<-data.frame(Class=df.test$had_covid, rf=rf.probability)

calplot<-(calibration(Class ~ rf, data=pred.prob, class=TRUE, cuts=10))

xyplot(calplot, auto.key=list(columns=1))



cal.data.index<-df.test$had_covid%>% createDataPartition(p=0.5, list=F)
cal.data<-df.test[cal.data.index, ]
final.test.data<-df.test[-cal.data.index, ]
#Predict on test-set without scaling to obtain raw pred prob in test set
rf.probs.nocal<-predict(rf.model, final.test.data, type="prob")
rf.pp.nocal<-rf.probs.nocal[,2]

#Apply model developed on training data to calibration dataset to obtain predictions
rf.probs.cal<-predict(rf.model, cal.data, type="prob")
rf.pp.cal<-rf.probs.cal[,2]

#Add to dataset with actual values from calibration data
calibrf.data.frame<-data.frame(rf.pp.cal, cal.data$had_covid)
colnames(calibrf.data.frame)<-c("x", "y")

#Use logistic regression to model predicted probabilities from calibration data to actual vales
calibrf.model<-glm(y ~ x, data=calibrf.data.frame, family = binomial)

#Apply calibration model above to raw predicted probabilities from test set
data.test.rf<-data.frame(rf.pp.nocal)
colnames(data.test.rf)<-c("x")
platt.data.rf<-predict(calibrf.model, data.test.rf, type="response")

platt.prob.rf<-data.frame(Class=final.test.data$had_covid, rf.platt=platt.data.rf, rf=rf.pp.nocal)

calplot.rf<-(calibration(Class ~ rf.platt+rf, data=platt.prob.rf, class=TRUE, cuts=10))
xyplot(calplot.rf, auto.key=list(columns=2))
```

